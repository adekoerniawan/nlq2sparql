{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G9YxjKIy5LDU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis step was just to be able to generate plots when running at colab.research.google.com\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This step was just to be able to generate plots when running at colab.research.google.com\n",
    "'''\n",
    "!apt-get -qq install -y graphviz && pip install -q pydot\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "u3fFvmBuzR4W",
    "outputId": "3bfef8e0-092f-4c2e-9f0c-7ee9457b00c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDownload the data from the AskNowQA space on gitHub\\nThis can be skipped if the train-data.json and test-data.json files are already \\nAvailable locally\\n'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Download the data from the AskNowQA space on gitHub\n",
    "This can be skipped if the train-data.json and test-data.json files are already \n",
    "Available locally\n",
    "'''\n",
    "!curl -O 'https://raw.githubusercontent.com/AskNowQA/LC-QuAD/data/train-data.json'\n",
    "!curl -O 'https://raw.githubusercontent.com/AskNowQA/LC-QuAD/data/test-data.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "ThHK7p6IlIoD",
    "outputId": "c3802a63-50c6-4b8f-8442-fbdc96fac107"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of records: 5000\n",
      "\n",
      "Sample pair of NLQ and SPARQL:\n",
      "\n",
      "How many movies did Stanley Kubrick direct?\n",
      "SELECT DISTINCT COUNT(?uri) WHERE {?uri <http://dbpedia.org/ontology/director> <http://dbpedia.org/resource/Stanley_Kubrick>  . }\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Parse the JSON data, splitting it into . The data source already split the data\n",
    "in to training and test sets; we recombine so that we can perform our own split.\n",
    "\n",
    "Each entry has the following keys:\n",
    "\n",
    "  - _id\n",
    "  - corrected_question\n",
    "  - intermediary_question\n",
    "  - sparql_query\n",
    "  - sparql_template_id\n",
    "\n",
    "We are interested in corrected_question (the NLQ to be translated) and \n",
    "sparql_query (the target for the translations).\n",
    "'''\n",
    "import json\n",
    "\n",
    "with open('train-data.json', 'r', encoding='utf-8') as f:\n",
    "  train_data = json.load(f)\n",
    "\n",
    "with open('test-data.json', 'r', encoding='utf-8') as f:\n",
    "  test_data = json.load(f)\n",
    "  \n",
    "source_data = train_data + test_data  \n",
    "  \n",
    "# quick inspection\n",
    "print('\\nNumber of records: {}'.format(len(source_data)))\n",
    "print('\\nSample pair of NLQ and SPARQL:\\n')\n",
    "print(source_data[0]['corrected_question'])\n",
    "print(source_data[0]['sparql_query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E--uGeDa8odn"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into the questions (NLQs) and queries (SPARQL)\n",
    "import numpy as np\n",
    "\n",
    "questions = [item['corrected_question'] for item in source_data]\n",
    "queries = [item['sparql_query'] for item in source_data]\n",
    "\n",
    "assert np.shape(questions) == np.shape(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ypQGzDrNnwIf",
    "outputId": "b34b2810-2190-4d9e-db92-0e129f0e8f0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved clean_questions.pkl\n",
      "saved clean_query_inputs.pkl\n",
      "saved clean_query_outputs.pkl\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The questions undergo fuller cleaning than the queries, removing punctuation etc.\n",
    "The queries are already normalized as they are valid SPARQL statements. Two sets\n",
    "are made from the queries:\n",
    "\n",
    "  - input queries, which have a start token prepended to each\n",
    "  - target queries, which have an end token appended to each\n",
    "\n",
    "There are a few SPARQL statements where curly braces don't have spaces between them\n",
    "and neighbouring tokens. We add a space around them if they don't exist.\n",
    "'''\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from pickle import dump, load\n",
    "import re\n",
    "\n",
    "default_filters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~'\n",
    "START_TOKEN = '<start>'\n",
    "END_TOKEN = '<end>'\n",
    "\n",
    "def load_clean_texts(filename):\n",
    "  with open(filename, 'rb') as f:\n",
    "    content = load(f)\n",
    "    print('loaded {}'.format(filename))\n",
    "    return content\n",
    "\n",
    "def save_texts(texts, filename):\n",
    "  with open(filename, 'wb') as f:\n",
    "    dump(texts, f)\n",
    "    print('saved {}'.format(filename))\n",
    "\n",
    "def separate_special_tokens(text):\n",
    "  text = re.sub(r'([^ ])([{}])', r'\\1 \\2', text)\n",
    "  text = re.sub(r'([{}])([^ ])', r'\\1 \\2', text)\n",
    "  text = re.sub(r'(\\?uri)(\\.)', r'\\1 \\2', text)\n",
    "  return text\n",
    "\n",
    "def clean_texts(texts, filename, filters=default_filters, lower=True, \n",
    "                start_token=None, end_token=None):\n",
    "  texts = [separate_special_tokens(text) for text in texts]\n",
    "  texts = [text_to_word_sequence(text, filters, lower) for text in texts]\n",
    "\n",
    "  if start_token is not None:\n",
    "    texts = [[start_token] + text for text in texts]\n",
    "\n",
    "  if end_token is not None:\n",
    "    texts = [text + [end_token] for text in texts]\n",
    "  \n",
    "  save_texts(texts, filename)\n",
    "\n",
    "clean_questions = clean_texts(questions, filename='clean_questions.pkl')\n",
    "clean_query_inputs = clean_texts(queries, filters='', lower=False, start_token=START_TOKEN,\n",
    "                                 filename='clean_query_inputs.pkl')\n",
    "clean_query_outputs = clean_texts(queries, filters='', lower=False, end_token=END_TOKEN,\n",
    "                                  filename='clean_query_outputs.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded clean_questions.pkl\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded clean_query_inputs.pkl\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "We plot the distributions of the words in the questions and queries\n",
    "to understand their different characteristics.\n",
    "'''\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_word_occurances(texts):\n",
    "    counter = Counter(chain.from_iterable(texts))\n",
    "    x = np.array(list(counter.values()))\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    logbins = np.logspace(np.log10(1), np.log10(np.max(x)), 20)\n",
    "    ax.hist(x, bins=logbins)\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylabel('Number of words')\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('Number of occurances')\n",
    "    plt.show()\n",
    "    \n",
    "clean_questions = load_clean_texts('clean_questions.pkl')\n",
    "plot_word_occurances(clean_questions)\n",
    "\n",
    "clean_queries = load_clean_texts('clean_query_inputs.pkl')\n",
    "plot_word_occurances(clean_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('?uri', 11010),\n",
      " ('.', 6465),\n",
      " ('<start>', 5000),\n",
      " ('WHERE', 5000),\n",
      " ('{', 5000),\n",
      " ('}', 5000),\n",
      " ('?x', 4740),\n",
      " ('SELECT', 4632),\n",
      " ('DISTINCT', 4632),\n",
      " ('<http://www.w3.org/1999/02/22-rdf-syntax-ns#type>', 1925),\n",
      " ('COUNT(?uri)', 658),\n",
      " ('ASK', 368),\n",
      " ('<http://dbpedia.org/ontology/TelevisionShow>', 236),\n",
      " ('<http://dbpedia.org/ontology/Person>', 132),\n",
      " ('<http://dbpedia.org/ontology/Film>', 113)]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The NLQs show the expected power law distribution of words - but the \n",
    "SPARQL queries have a set of high-frequency words that don't fit in \n",
    "that distribution. We can see below that those are a mixture of keywords\n",
    "and special tokens, the core \"is a\" predicate:\n",
    "\n",
    "    <http://www.w3.org/1999/02/22-rdf-syntax-ns#type>,\n",
    "\n",
    "plus a few types that were somewhat over-represented in the generation\n",
    "of the queries, such as television shows.\n",
    "'''\n",
    "import pprint\n",
    "\n",
    "query_counter = Counter(chain.from_iterable(clean_queries))\n",
    "top_query_tokens = query_counter.most_common(15)\n",
    "\n",
    "pprint.pprint(top_query_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L3wZ92RoOYML"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "class Encoder:\n",
    "  '''\n",
    "  Class creates a tokenizer used for vectorizing texts. It can also create a one-hot\n",
    "  encoded version of the text vectors, which as the target of the predictions.\n",
    "  '''\n",
    "\n",
    "  def __init__(self, texts):\n",
    "    self.texts = texts\n",
    "    self.tokenizer = Tokenizer()\n",
    "    self.tokenizer.fit_on_texts(self.texts)\n",
    "    self.inverter = dict((v, k) for k, v in self.tokenizer.word_index.items())\n",
    "    self.maxlen = max(len(text) for text in self.texts)\n",
    "    self.vocab_size = len(self.tokenizer.word_index) + 1    \n",
    "    self.report()\n",
    "\n",
    "  def report(self):\n",
    "    print('---')\n",
    "    print('vocab size: {}'.format(self.vocab_size))\n",
    "    print('sequence lengths: {}'.format(self.maxlen))\n",
    "    print('sample: \"{}\"'.format(' '.join(self.texts[100])))\n",
    "    \n",
    "    sample_word = self.texts[0][0]    \n",
    "    hot_encoded_sample_word = self.to_categorical(texts=[sample_word.split()], maxlen=1)\n",
    "    decoded_hot_encoded = self.decode_categorical(one_hot_sequence=hot_encoded_sample_word)\n",
    "    print('decoded encoded sample word: {}'.format(decoded_hot_encoded))\n",
    "  \n",
    "  def encode_text(self, text, pad_to_length):\n",
    "    return self.encode_texts(texts=[text.split()], maxlen=pad_to_length)\n",
    "  \n",
    "  def encode_texts(self, texts, maxlen=None):\n",
    "    if maxlen is None:\n",
    "      maxlen = self.maxlen\n",
    "    sequences = self.tokenizer.texts_to_sequences(texts)\n",
    "    return pad_sequences(sequences, maxlen=maxlen, padding='post')\n",
    "\n",
    "  def encoded(self):\n",
    "    return self.encode_texts(self.texts)\n",
    "\n",
    "  def decode_tokens(self, sequence):\n",
    "    sentence = list()\n",
    "    for token in sequence:\n",
    "      if token == 0:\n",
    "        break\n",
    "      sentence.append(self.inverter[token])\n",
    "    return ' '.join(sentence)\n",
    "\n",
    "  def to_categorical(self, texts, maxlen=None):\n",
    "    encoded = self.encode_texts(texts, maxlen)\n",
    "    categorical = [to_categorical(text, num_classes=self.vocab_size) for text in encoded]\n",
    "    return np.array(categorical).reshape(encoded.shape[0], encoded.shape[1], self.vocab_size)\n",
    "\n",
    "  def categorical_encoded(self):\n",
    "    encoded = self.encoded()\n",
    "    return self.to_categorical(encoded)\n",
    "          \n",
    "  def decode_categorical(self, one_hot_sequence):\n",
    "    sequence = [np.argmax(v) for v in one_hot_sequence]\n",
    "    return self.decode_tokens(sequence)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mJjnOSRgDNTR"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from matplotlib import pyplot\n",
    "import re\n",
    "\n",
    "class QuestionToQuery:\n",
    "  '''\n",
    "  Instance of the training + inference models, used as convenience to run \n",
    "  different hyperparameters.\n",
    "  '''\n",
    "\n",
    "  def __init__(self, latent_dim, epochs, batch_size, optimizer, dropout, recurrent_dropout,\n",
    "               questions_vocab_size, query_vocab_size, question_length, query_length):\n",
    "\n",
    "    self.latent_dim = latent_dim\n",
    "    self.epochs = epochs\n",
    "    self.batch_size = batch_size\n",
    "    self.optimizer = optimizer\n",
    "    self.dropout = dropout\n",
    "    self.recurrent_dropout = recurrent_dropout\n",
    "    \n",
    "    self.questions_vocab_size = questions_vocab_size\n",
    "    self.query_vocab_size = query_vocab_size\n",
    "    self.question_length = question_length\n",
    "    self.query_length = query_length\n",
    "    dirty_name = 'model_{}_{}_{}_{}_{}_{}'.format(latent_dim, epochs, batch_size, optimizer,\n",
    "                                                 dropout, recurrent_dropout)\n",
    "    self.name = re.sub(r'\\.', '', dirty_name)\n",
    "    self.init_training_model()\n",
    "    self.init_inference_model()\n",
    "  \n",
    "  def init_training_model(self):\n",
    "    '''\n",
    "    The Training Model trains embedding and LSTM layers, and the encoder state.\n",
    "    '''\n",
    "    self.encoder_inputs = Input(shape=(None,))\n",
    "\n",
    "    x = Embedding(input_dim=self.questions_vocab_size,\n",
    "                  output_dim=self.latent_dim,\n",
    "                  mask_zero=True,\n",
    "                  input_length=self.question_length)\n",
    "    encoder_embedding_outputs = x(self.encoder_inputs)\n",
    "\n",
    "    \n",
    "    x = LSTM(units=self.latent_dim, \n",
    "             return_state=True, \n",
    "             dropout=self.dropout,\n",
    "             recurrent_dropout=self.recurrent_dropout)\n",
    "    _, state_h, state_c = x(encoder_embedding_outputs)\n",
    "    self.encoder_states = [state_h, state_c]\n",
    "\n",
    "    self.decoder_inputs = Input(shape=(None,))\n",
    "    \n",
    "    x = Embedding(input_dim=self.query_vocab_size,\n",
    "                  output_dim=self.latent_dim,\n",
    "                  mask_zero=True,\n",
    "                  input_length=self.query_length)\n",
    "    self.decoder_embedding_outputs = x(self.decoder_inputs)\n",
    "\n",
    "    self.decoder_lstm = LSTM(units=self.latent_dim, return_sequences=True, return_state=True,\n",
    "                             dropout=0.2, recurrent_dropout=0.2)\n",
    "    decoder_lstm_outputs, _, _ = self.decoder_lstm(self.decoder_embedding_outputs, \n",
    "                                                   initial_state=self.encoder_states)\n",
    "    \n",
    "    self.decoder_dense = Dense(units=self.query_vocab_size, activation='softmax')\n",
    "    decoder_outputs = self.decoder_dense(decoder_lstm_outputs)\n",
    "\n",
    "    self.training_model = Model(inputs=[self.encoder_inputs, self.decoder_inputs], \n",
    "                                outputs=decoder_outputs)\n",
    "    self.training_model.compile(optimizer=self.optimizer,\n",
    "                                loss='categorical_crossentropy', \n",
    "                                metrics=['accuracy'])\n",
    "\n",
    "  def init_inference_model(self):\n",
    "    '''\n",
    "    Model for generating predictions of SPARQL queries from questions. Uses inputs from\n",
    "    the training model.\n",
    "    '''\n",
    "    self.encoder_model = Model(inputs=self.encoder_inputs, outputs=self.encoder_states)\n",
    "    encoder_outputs = Input(shape=(None, self.latent_dim))\n",
    "\n",
    "    input_h = Input(shape=(self.latent_dim,))\n",
    "    input_c = Input(shape=(self.latent_dim,))\n",
    "    input_states = [input_h, input_c]\n",
    "\n",
    "    inference_lstm_outputs, inference_h, inference_c = \\\n",
    "      self.decoder_lstm(self.decoder_embedding_outputs, initial_state=input_states)\n",
    "\n",
    "    inference_states = [inference_h, inference_c]\n",
    "    inference_outputs = self.decoder_dense(inference_lstm_outputs)\n",
    "\n",
    "    self.inference_model = Model([self.decoder_inputs] + input_states,\n",
    "                                 [inference_outputs] + inference_states)\n",
    "  \n",
    "  def summary(self):\n",
    "    print(self.training_model.summary())\n",
    "    print(self.encoder_model.summary())\n",
    "    print(self.inference_model.summary())\n",
    "    \n",
    "  def plot_models(self):\n",
    "    plot_model(training_model, to_file='training_model.png', show_shapes=True)    \n",
    "    plot_model(encoder_model, to_file='encoder_model.png', show_shapes=True)    \n",
    "    plot_model(inference_model, to_file='inference_model.png', show_shapes=True)\n",
    "    \n",
    "  def train(self, questions, query_inputs, query_outputs):\n",
    "    assert len(questions) == len(query_inputs)\n",
    "    assert len(query_inputs) == len(query_outputs)\n",
    "    \n",
    "    train_X = [questions, query_inputs]\n",
    "    train_y = query_outputs\n",
    "\n",
    "    checkpoint = ModelCheckpoint('training_{}.h5'.format(self.name), monitor='val_loss', verbose=1, \n",
    "                                 save_best_only=True, mode='min')\n",
    "    self.history = self.training_model.fit(x=train_X, y=train_y, \n",
    "                                           batch_size=self.batch_size, \n",
    "                                           epochs=self.epochs, \n",
    "                                           validation_split=0.1,\n",
    "                                           callbacks=[checkpoint],\n",
    "                                           verbose=2)\n",
    "  \n",
    "  def plot_training(self):\n",
    "    pyplot.plot(self.history.history['loss'])\n",
    "    pyplot.plot(self.history.history['val_loss'])\n",
    "    pyplot.title('Training vs Validation Loss')\n",
    "    pyplot.ylabel('Loss')\n",
    "    pyplot.xlabel('Epoch')\n",
    "    pyplot.legend(['train', 'val'], loc='upper left')\n",
    "    pyplot.savefig('loss_{}'.format(self.name))\n",
    "    pyplot.gcf().clear()\n",
    "\n",
    "    pyplot.plot(self.history.history['acc'])\n",
    "    pyplot.plot(self.history.history['val_acc'])\n",
    "    pyplot.title('Training vs Validation Accuracy')\n",
    "    pyplot.ylabel('Accuracy')\n",
    "    pyplot.xlabel('Epoch')\n",
    "    pyplot.legend(['train', 'val'], loc='upper left')\n",
    "    pyplot.savefig('accuracy_{}'.format(self.name))\n",
    "    pyplot.gcf().clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-P8YrLHjntxw"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "class ModelEvaluation:\n",
    "  '''\n",
    "  Evaluates the inference model using the BLEU score for 1-4 grams. The evaluation\n",
    "  is done comparing predictions from questions to target queries \n",
    "  '''\n",
    "\n",
    "  def __init__(self, model, query_inputs_encoder, query_outputs_encoder, query_length):\n",
    "    self.model = model\n",
    "    self.query_inputs_encoder = query_inputs_encoder\n",
    "    self.query_outputs_encoder = query_outputs_encoder\n",
    "    self.query_length = query_length\n",
    "\n",
    "  def question_to_query(self, question):\n",
    "    states_value = self.model.encoder_model.predict(question)   \n",
    "    inference_input = self.query_inputs_encoder.encode_text(START_TOKEN, \n",
    "                                                            pad_to_length=self.query_length)\n",
    "    decoded_sentence = list()\n",
    "\n",
    "    while True:\n",
    "      output_tokens, h, c = self.model.inference_model.predict([inference_input, \n",
    "                                                                states_value[0], \n",
    "                                                                states_value[1]])\n",
    "      \n",
    "      decoded_word = self.query_outputs_encoder.decode_categorical(output_tokens)\n",
    "      \n",
    "      if (decoded_word == END_TOKEN or len(decoded_sentence) >= self.query_outputs_encoder.maxlen):\n",
    "        break\n",
    "\n",
    "      decoded_sentence.append(decoded_word)\n",
    "      inference_input = self.query_inputs_encoder.encode_text(decoded_word, \n",
    "                                                              pad_to_length=self.query_length)\n",
    "      states_value = h, c\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "  def run(self, questions, target_queries):\n",
    "    target = list()\n",
    "    predicted = list()\n",
    "    for i, question in enumerate(questions):\n",
    "      target_query = self.query_outputs_encoder.decode_categorical(target_queries[i])\n",
    "      target.append(target_query.split())\n",
    "\n",
    "      predicted_query = self.question_to_query(question)\n",
    "      predicted.append(predicted_query)\n",
    "\n",
    "      if i < 10:\n",
    "        print('\\nSample translation:')\n",
    "        print('Question: {}'.format(questions_encoder.decode_tokens(question)))\n",
    "        print('Target SPARQL: {}'.format(target_query))\n",
    "        print('Predicted SPARQL: {}'.format(' '.join(predicted_query)))\n",
    "\n",
    "    bleu_1 = corpus_bleu(target, predicted, weights=(1.0, 0, 0, 0))\n",
    "    bleu_2 = corpus_bleu(target, predicted, weights=(0.5, 0.5, 0, 0))\n",
    "    bleu_3 = corpus_bleu(target, predicted, weights=(0.333, 0.333, 0.333, 0))\n",
    "    bleu_4 = corpus_bleu(target, predicted, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "\n",
    "    return dict(bleu_1=bleu_1, bleu_2=bleu_2, bleu_3=bleu_3, bleu_4=bleu_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 955
    },
    "colab_type": "code",
    "id": "yZ2vi_e-ZO2b",
    "outputId": "cfe83981-1a70-4182-a694-14fae877736e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded clean_questions.pkl\n",
      "loaded clean_query_inputs.pkl\n",
      "loaded clean_query_outputs.pkl\n",
      "---\n",
      "vocab size: 7116\n",
      "sequence lengths: 25\n",
      "sample: \"who won a norbert wiener award for social and professional responsibility\"\n",
      "decoded encoded sample word: how\n",
      "---\n",
      "vocab size: 4728\n",
      "sequence lengths: 18\n",
      "sample: \"<start> SELECT DISTINCT ?uri WHERE { ?uri <http://dbpedia.org/property/prizes> <http://dbpedia.org/resource/Norbert_Wiener_Award_for_Social_and_Professional_Responsibility> . }\"\n",
      "decoded encoded sample word: <start>\n",
      "---\n",
      "vocab size: 4728\n",
      "sequence lengths: 18\n",
      "sample: \"SELECT DISTINCT ?uri WHERE { ?uri <http://dbpedia.org/property/prizes> <http://dbpedia.org/resource/Norbert_Wiener_Award_for_Social_and_Professional_Responsibility> . } <end>\"\n",
      "decoded encoded sample word: select\n",
      "====================================================================================================\n",
      "Running hyperparameter set: latent_dim: 64, epochs: 100, batch_size: 32, optimizer: adam, dropout: 0.0\n",
      "Train on 4050 samples, validate on 450 samples\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Run the training and evaluation, varying the following hyper-parameters:\n",
    "\n",
    "    - number of units\n",
    "    - epochs\n",
    "    - batch size\n",
    "    \n",
    "'''\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "clean_questions = load_clean_texts('clean_questions.pkl')\n",
    "clean_query_inputs = load_clean_texts('clean_query_inputs.pkl')\n",
    "clean_query_outputs = load_clean_texts('clean_query_outputs.pkl')\n",
    "\n",
    "questions_encoder = Encoder(clean_questions)\n",
    "query_inputs_encoder = Encoder(clean_query_inputs)\n",
    "query_outputs_encoder = Encoder(clean_query_outputs)\n",
    "\n",
    "encoded_questions = questions_encoder.encode_texts(clean_questions)\n",
    "encoded_query_inputs = query_inputs_encoder.encode_texts(clean_query_inputs)\n",
    "encoded_query_outputs = query_outputs_encoder.to_categorical(clean_query_outputs)\n",
    "\n",
    "questions_train, questions_test, query_inputs_train, query_inputs_test, query_outputs_train, \\\n",
    "  query_outputs_test = train_test_split(encoded_questions, encoded_query_inputs, \n",
    "                                        encoded_query_outputs, test_size=0.1, random_state=9)\n",
    "\n",
    "questions_vocab_size = questions_encoder.vocab_size\n",
    "query_vocab_size = query_inputs_encoder.vocab_size\n",
    "\n",
    "hyperparam_sets = itertools.product([64, 128, 256], [32, 64], ['adam', 'rmsprop'], [0.0, 0.5])\n",
    "epochs = 100\n",
    "\n",
    "for latent_dim, batch_size, optimizer, dropout in hyperparam_sets:\n",
    "  print('=' * 100)\n",
    "  print('Running hyperparameter set: latent_dim: {}, epochs: {}, batch_size: {}, optimizer: {}, dropout: {}'\n",
    "        .format(latent_dim, epochs, batch_size, optimizer, dropout))\n",
    "  \n",
    "  model = QuestionToQuery(latent_dim=latent_dim, \n",
    "                          epochs=100,\n",
    "                          batch_size=batch_size,\n",
    "                          optimizer=optimizer,\n",
    "                          dropout=dropout, \n",
    "                          recurrent_dropout=dropout,\n",
    "                          questions_vocab_size=questions_vocab_size, \n",
    "                          query_vocab_size=query_vocab_size,\n",
    "                          question_length=questions_encoder.maxlen, \n",
    "                          query_length=query_inputs_encoder.maxlen)\n",
    "\n",
    "  model.train(questions=questions_train, \n",
    "              query_inputs=query_inputs_train,\n",
    "              query_outputs=query_outputs_train)\n",
    "  model.plot_training()\n",
    "\n",
    "  evaluation = ModelEvaluation(model=model,\n",
    "                               query_inputs_encoder=query_inputs_encoder,\n",
    "                               query_outputs_encoder=query_outputs_encoder,\n",
    "                               query_length=query_inputs_encoder.maxlen)\n",
    "  \n",
    "  training_bleu_scores = evaluation.run(questions=questions_train, \n",
    "                                        target_queries=query_outputs_train)\n",
    "  print('Training BLEU scores: {}\\n'.format(training_bleu_scores))\n",
    "  \n",
    "  test_bleu_scores = evaluation.run(questions=questions_test, \n",
    "                                    target_queries=query_outputs_test)\n",
    "  print('Test BLEU scores: {}\\n'.format(test_bleu_scores))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "capstone-project.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
